# LOGOS LRB — tools — BOOK (LIVE 2025-10-05_16-54-43)

- Branch: `main`
- Commit: `54d27563ee2c`
- rustc: `rustc 1.89.0 (29483883e 2025-08-04)`  cargo: `cargo 1.89.0 (c24e10642 2025-06-23)`

## Project tree (tools)
```text
.
bench
bench/go
go_test
load
sdk
sdk/go
sdk/ts
```

## Files list (tools)
```text
./admin_cli.sh
./batch.json
./bench/go/bench.go
./book_make.sh
./book_restore.sh
./gen_full_codemap.py
./go_test/go.mod
./go_test/go.sum
./go_test/main.go
./go_test/two_rids.go
./k6_smoke.js
./load/go.mod
./load/go.sum
./load/load_submit_tx.go
./load_healthz.sh
./lrb_audit.sh
./make_book_and_push.sh
./make_codebook.sh
./make_full_book.sh
./make_full_snapshot_live.sh
./prepare_payer.sh
./repo_audit.sh
./sdk/go/logosapi.go
./sdk/go/main.go
./sdk/ts/index.mjs
./sdk/ts/sdk_test.mjs
./targets.jsonl
./test_tx.sh
./tx_load.sh
./tx_one.sh
./vegeta_submit.sh
./vegeta_submit_live.sh
```

## Files content (tools)

### `tools/./admin_cli.sh`

```
#!/usr/bin/env bash
set -euo pipefail

NODE_URL="${NODE_URL:-http://127.0.0.1:8080}"

# --- helpers ---
get_env() {
  systemctl show -p Environment logos-node.service \
    | sed -n 's/^Environment=//p' \
    | tr ' ' '\n' \
    | sed 's/"//g'
}

ENV_CACHE="$(get_env || true)"
get_var() { echo "$ENV_CACHE" | sed -n "s/^$1=//p" | head -n1; }

AK="${AK:-$(get_var LRB_ADMIN_KEY || true)}"
BK="${BK:-$(get_var LRB_BRIDGE_KEY || true)}"

require_admin_key() {
  if [[ -z "${AK:-}" || "$AK" == "CHANGE_ADMIN_KEY" ]]; then
    echo "[!] LRB_ADMIN_KEY не задан или дефолтный. Укажи AK=... в окружении или в keys.conf" >&2
    exit 1
  fi
}
require_bridge_key() {
  if [[ -z "${BK:-}" || "$BK" == "CHANGE_ME" ]]; then
    echo "[!] LRB_BRIDGE_KEY не задан или дефолтный. Укажи BK=... в окружении или в keys.conf" >&2
    exit 1
  fi
}

jq_or_cat() {
  if command -v jq >/dev/null 2>&1; then jq .; else cat; fi
}

usage() {
cat <<'EOF'
admin_cli.sh — удобные команды для LOGOS LRB (prod)

ENV:
  NODE_URL=http://127.0.0.1:8080     # адрес ноды (по умолчанию)
  AK=<admin-key>                     # можно переопределить, иначе берется из systemd
  BK=<bridge-key>                    # можно переопределить, иначе берется из systemd

Команды:
  health                      — /healthz
  head                        — /head
  node-info                   — /node/info
  validators                  — /admin/validators
  metrics [grep]              — /metrics (опциональный grep)

  snapshot-json               — GET /admin/snapshot (требует AK)
  snapshot-file [name]        — GET /admin/snapshot/file?name=NAME (требует AK)
  restore <abs_path.json>     — POST /admin/restore (требует AK)

  deposit <rid> <amount> <ext_txid>         — POST /bridge/deposit (требует BK)
  redeem  <rid> <amount> <request_id>       — POST /bridge/redeem (требует BK)
  verify  <ticket> <vk_b58> <signature_b64> — POST /bridge/verify

  account-txs <rid> [limit]   — GET /account/:rid/txs?limit=N

Примеры:
  ./admin_cli.sh head
  ./admin_cli.sh validators
  AK=$(systemctl show -p Environment logos-node.service | sed -n 's/.*LRB_ADMIN_KEY=\([^ ]*\).*/\1/p') \
    ./admin_cli.sh snapshot-json
  BK=$(systemctl show -p Environment logos-node.service | sed -n 's/.*LRB_BRIDGE_KEY=\([^ ]*\).*/\1/p') \
    ./admin_cli.sh deposit RID_A 12345 ext-1
EOF
}

cmd="${1:-}"
case "$cmd" in
  ""|-h|--help|help) usage; exit 0 ;;
esac
shift || true

case "$cmd" in
  health)
    curl -s "$NODE_URL/healthz" | jq_or_cat
    ;;

  head)
    curl -s "$NODE_URL/head" | jq_or_cat
    ;;

  node-info)
    curl -s "$NODE_URL/node/info" | jq_or_cat
    ;;

  validators)
    curl -s "$NODE_URL/admin/validators" | jq_or_cat
    ;;

  metrics)
    body="$(curl -s "$NODE_URL/metrics")"
    if [[ $# -gt 0 ]]; then echo "$body" | grep -E "$*" || true; else echo "$body"; fi
    ;;

  snapshot-json)
    require_admin_key
    curl -s -H "X-Admin-Key: $AK" "$NODE_URL/admin/snapshot" | jq_or_cat
    ;;

  snapshot-file)
    require_admin_key
    name="${1:-snap-$(date +%s).json}"
    curl -s -H "X-Admin-Key: $AK" "$NODE_URL/admin/snapshot/file?name=$name" | jq_or_cat
    ;;

  restore)
    require_admin_key
    file="${1:-}"
    [[ -z "$file" ]] && { echo "[!] usage: restore /var/lib/logos/snapshots/<file>.json" >&2; exit 1; }
    curl -s -X POST -H "content-type: application/json" -H "X-Admin-Key: $AK" \
      "$NODE_URL/admin/restore" \
      -d "{\"file\":\"$file\"}" | jq_or_cat
    ;;

  deposit)
    require_bridge_key
    rid="${1:-}"; amt="${2:-}"; xtx="${3:-}"
    [[ -z "$rid" || -z "$amt" || -z "$xtx" ]] && { echo "[!] usage: deposit <rid> <amount> <ext_txid>" >&2; exit 1; }
    curl -s -X POST "$NODE_URL/bridge/deposit" \
      -H "content-type: application/json" -H "X-Bridge-Key: $BK" \
      -d "{\"rid\":\"$rid\",\"amount\":$amt,\"ext_txid\":\"$xtx\"}" | jq_or_cat
    ;;

  redeem)
    require_bridge_key
    rid="${1:-}"; amt="${2:-}"; reqid="${3:-}"
    [[ -z "$rid" || -z "$amt" || -z "$reqid" ]] && { echo "[!] usage: redeem <rid> <amount> <request_id>" >&2; exit 1; }
    curl -s -X POST "$NODE_URL/bridge/redeem" \
      -H "content-type: application/json" -H "X-Bridge-Key: $BK" \
      -d "{\"rid\":\"$rid\",\"amount\":$amt,\"request_id\":\"$reqid\"}" | jq_or_cat
    ;;

  verify)
    ticket="${1:-}"; vk_b58="${2:-}"; sig_b64="${3:-}"
    [[ -z "$ticket" || -z "$vk_b58" || -z "$sig_b64" ]] && { echo "[!] usage: verify <ticket> <vk_b58> <signature_b64>" >&2; exit 1; }
    curl -s -X POST "$NODE_URL/bridge/verify" \
      -H "content-type: application/json" \
      -d "{\"ticket\":\"$ticket\",\"vk_b58\":\"$vk_b58\",\"signature_b64\":\"$sig_b64\"}" | jq_or_cat
    ;;

  account-txs)
    rid="${1:-}"; limit="${2:-100}"
    [[ -z "$rid" ]] && { echo "[!] usage: account-txs <rid> [limit]" >&2; exit 1; }
    curl -s "$NODE_URL/account/$rid/txs?limit=$limit" | jq_or_cat
    ;;

  *)
    echo "[!] unknown command: $cmd" >&2
    usage
    exit 1
    ;;
esac
```

### `tools/./batch.json`

```
```

### `tools/./book_make.sh`

```
#!/usr/bin/env bash
set -euo pipefail

# Куда писать книгу
DATE_UTC=$(date -u +%Y-%m-%dT%H-%M-%SZ)
BOOK="docs/LOGOS_LRB_BOOK_${DATE_UTC}.txt"

# Корень репозитория (чтобы пути были относительные)
REPO_ROOT="/root/logos_lrb"
cd "$REPO_ROOT"

echo "[*] Building book: $BOOK"
mkdir -p docs

# --- списки включений/исключений ---
# Git-трекаемые файлы + критичные конфиги вне репы
INCLUDE_LIST="$(mktemp)"
EXTRA_LIST="$(mktemp)"

# 1) всё полезное из git (код/конфиги), без мусора
git ls-files \
  | grep -Ev '^(\.gitignore|README\.md|LICENSE|^docs/LOGOS_LRB_BOOK_|^docs/.*\.pdf$)' \
  | grep -Ev '(^target/|/target/|^node_modules/|/node_modules/|\.DS_Store|\.swp$|\.sqlite$|/data\.sled|/data\.sled/|\.pem$|\.key$)' \
  > "$INCLUDE_LIST"

# 2) системные файлы вне репы (если существуют)
add_extra() { [[ -f "$1" ]] && echo "$1" >> "$EXTRA_LIST"; }
add_extra "/etc/systemd/system/logos-node.service"
for f in /etc/systemd/system/logos-node.service.d/*.conf; do [[ -f "$f" ]] && echo "$f" >> "$EXTRA_LIST"; done
add_extra "/etc/nginx/conf.d/10_lrb_https.conf"
add_extra "/etc/prometheus/prometheus.yml"
for f in /etc/prometheus/rules/*.yml; do [[ -f "$f" ]] && echo "$f" >> "$EXTRA_LIST"; done
# Grafana provisioning/дашборды (если есть)
for f in /etc/grafana/provisioning/dashboards/*.yaml /var/lib/grafana/dashboards/*.json; do
  [[ -f "$f" ]] && echo "$f" >> "$EXTRA_LIST"
done
# OpenAPI (в репе уже есть), APK/лендинг укажем ссылкой — бинарники в книгу не кладём

# --- заголовок книги ---
{
  echo "LOGOS LRB — FULL LIVE BOOK (${DATE_UTC})"
  echo
  echo "Содержимое: весь код репозитория + ключевая инфраструктура (systemd/nginx/prometheus/grafana),"
  echo "формат: секции BEGIN/END FILE c sha256 и блочным EOF. Бинарники (APK, sled, pem) не включаются."
  echo
  echo "Репозиторий: $REPO_ROOT"
  echo
} > "$BOOK"

emit_file () {
  local src="$1" dst
  # внутри репо пишем относительные пути; вне — абсолютные
  if [[ "$src" == $REPO_ROOT/* ]]; then
    dst="/${src#$REPO_ROOT/}"
  else
    dst="$src"
  fi
  # пропуск «мусора»
  if [[ -d "$src" ]]; then return 0; fi
  if [[ ! -f "$src" ]]; then return 0; fi
  # вычисляем sha256
  local sum
  sum=$(sha256sum "$src" | awk '{print $1}')
  {
    echo "===== BEGIN FILE $dst ====="
    echo "# sha256: $sum"
    echo "<<'EOF'"
    cat "$src"
    echo "EOF"
    echo "===== END FILE $dst ====="
    echo
  } >> "$BOOK"
}

echo "[*] Emitting repo files..."
while IFS= read -r p; do emit_file "$REPO_ROOT/$p"; done < "$INCLUDE_LIST"

echo "[*] Emitting extra system files..."
if [[ -s "$EXTRA_LIST" ]]; then
  while IFS= read -r p; do emit_file "$p"; done < "$EXTRA_LIST"
fi

# --- прикладываем «паспорт» окружения ---
{
  echo "===== BEGIN FILE /docs/ENV_SNAPSHOT.txt ====="
  echo "# sha256: N/A"
  echo "<<'EOF'"
  echo "[systemd env]"
  systemctl show logos-node -p Environment | sed 's/^Environment=//'
  echo
  echo "[nginx -v]"
  nginx -v 2>&1 || true
  echo
  echo "[prometheus rules list]"
  ls -1 /etc/prometheus/rules 2>/dev/null || true
  echo
  echo "[grafana dashboards list]"
  ls -1 /var/lib/grafana/dashboards 2>/dev/null || true
  echo "EOF"
  echo "===== END FILE /docs/ENV_SNAPSHOT.txt ====="
  echo
} >> "$BOOK"

echo "[*] Book is ready: $BOOK"
```

### `tools/./book_restore.sh`

```
#!/usr/bin/env bash
set -euo pipefail

BOOK="${1:-}"
if [[ -z "$BOOK" || ! -f "$BOOK" ]]; then
  echo "usage: $0 /path/to/LOGOS_LRB_BOOK_*.txt"; exit 1
fi

echo "[*] Restoring files from: $BOOK"
RESTORED=0
BADHASH=0

# прочитаем книгу и вытащим секции
# формат: BEGIN FILE <path>\n# sha256: <hex>\n<<'EOF'\n...EOF\nEND FILE
awk '
  /^===== BEGIN FILE / {
    inblock=1
    path=""
    sha=""
    gsub(/^===== BEGIN FILE /,"")
    gsub(/ =====$/,"")
    path=$0
    next
  }
  inblock && /^# sha256:/ {
    sha=$2
    next
  }
  inblock && /^<<'\''EOF'\''/ { collecting=1; content=""; next }
  collecting && /^EOF$/ { collecting=0; inblock=2; next }
  inblock==1 && !collecting { next }
  collecting { content = content $0 "\n"; next }
  inblock==2 && /^===== END FILE / {
    # записываем файл
    # создадим директорию
    cmd = "mkdir -p \"" path "\""
    sub(/\/[^\/]+$/, "", cmdpath=path) # dir part
    if (cmdpath != "") {
      system("mkdir -p \"" cmdpath "\"")
    }
    # записываем
    f = path
    gsub(/\r$/,"",content)
    # защитимся от /etc/... если нет прав — предложим sudo
    # но здесь просто пишем как есть
    outfile = path
    # если путь абсолютный, пишем в тот же абсолютный; если относительный — относительно cwd
    # создадим временный и заменим
    tmpfile = outfile ".tmp.restore"
    # в shell передам через printf
    print content > tmpfile
    close(tmpfile)
    # проверка sha256 если есть
    if (sha != "" && sha != "N/A") {
      cmdsum = "sha256sum \"" tmpfile "\" | awk '\''{print $1}'\''"
      cmdsum | getline got
      close(cmdsum)
      if (got != sha) {
        print "[WARN] sha256 mismatch for " outfile " expected=" sha " got=" got
        BADHASH++
      }
    }
    system("install -m 0644 \"" tmpfile "\" \"" outfile "\"")
    system("rm -f \"" tmpfile "\"")
    print "[OK] restored " outfile
    RESTORED++
    inblock=0
    next
  }
  END {
    # summary в AWK не выведем; сделаем в оболочке
  }
' "$BOOK"

echo "[*] Restored files: $RESTORED"
if [[ "${BADHASH:-0}" -gt 0 ]]; then
  echo "[!] WARNING: sha256 mismatches: $BADHASH"
fi

echo "[*] Done. Проверь права на системные файлы, возможно потребуется sudo chown/chmod."
```

### `tools/./gen_full_codemap.py`

```
#!/usr/bin/env python3
# gen_full_codemap.py — cоздаёт единый текстовый слепок исходников из заданных директорий.
# Использование:
#   python3 gen_full_codemap.py OUTPUT.txt DIR1 [DIR2 ...]
#
# Пример:
#   python3 gen_full_codemap.py /root/logos_snapshot/SNAPSHOT_$(date +%F_%H%M).txt /root/logos_lrb /root/logos_rsp

import os, sys, hashlib, time

OK_EXT = {
    '.rs','.py','.tsx','.ts','.js','.jsx','.go',
    '.html','.htm','.css','.scss','.md','.txt',
    '.yaml','.yml','.toml','.ini','.cfg','.conf',
    '.sh','.bash','.zsh','.sql','.proto','.graphql',
    '.env.example','.service','.timer'
}

EXCLUDE_DIR_PREFIXES = (
    '.git','target','node_modules','build','dist','out','venv','.venv','__pycache__',
    '.idea','.vscode','.fleet','.DS_Store','coverage','.pytest_cache',
    '.cargo','.gradle','android/app/build','ios/Pods','.dart_tool',
    'tools/.venv','tools/venv','.husky'
)

EXCLUDE_FILE_PATTERNS = (
    '.env',        # любые .env (чтобы не потянуть реальные секреты)
    '.pem','.key','.crt','.p12','.keystore','.jks',
    '.sqlite','.db','.db3','.sqlite3',
    '.lock','.bin','.wasm','.o','.a'
)

MAX_FILE_BYTES = 400_000       # не включать слишком большие файлы
MAX_TOTAL_BYTES = 300_000_000  # общий предел (300 МБ, чтобы не улететь в космос)

def is_excluded_dir(path):
    norm = path.replace('\\','/')
    parts = norm.split('/')
    for p in parts:
        for ex in EXCLUDE_DIR_PREFIXES:
            if p == ex or norm.startswith(ex + '/'):
                return True
    return False

def is_ok_file(path):
    # исключить секреты/бинарники по шаблонам имени
    low = path.lower()
    for pat in EXCLUDE_FILE_PATTERNS:
        if low.endswith(pat) or f"/{pat}" in low:
            return False
    # по расширениям
    _, ext = os.path.splitext(path)
    if ext.lower() in OK_EXT:
        try:
            if os.path.getsize(path) <= MAX_FILE_BYTES:
                return True
        except FileNotFoundError:
            return False
    return False

def sha256_of_file(path):
    h = hashlib.sha256()
    with open(path,'rb') as r:
        while True:
            b = r.read(1024*1024)
            if not b: break
            h.update(b)
    return h.hexdigest()

def collect_files(roots):
    out = []
    for root in roots:
        root = os.path.abspath(root)
        if not os.path.isdir(root):
            continue
        for dp, dn, fn in os.walk(root):
            # пропуск скрытых/исключённых директорий
            norm_dp = dp.replace('\\','/')
            if is_excluded_dir(norm_dp):
                dn[:] = []  # не спускаться ниже
                continue
            for f in fn:
                p = os.path.join(dp,f)
                norm = p.replace('\\','/')
                # пропускаем скрытые файлы
                if any(seg.startswith('.') and seg not in ('.env.example',) for seg in norm.split('/')):
                    # .env.example оставляем
                    pass
                if is_ok_file(norm):
                    out.append(norm)
    out = sorted(set(out))
    return out

def main():
    if len(sys.argv) < 3:
        print("Usage: gen_full_codemap.py OUTPUT.txt DIR1 [DIR2 ...]", file=sys.stderr)
        sys.exit(1)
    output = os.path.abspath(sys.argv[1])
    roots  = sys.argv[2:]
    files  = collect_files(roots)
    ts = time.strftime('%Y-%m-%d %H:%M:%S')

    total_written = 0
    os.makedirs(os.path.dirname(output), exist_ok=True)
    with open(output, 'w', encoding='utf-8', errors='replace') as w:
        w.write("# FULL CODE SNAPSHOT\n")
        w.write(f"Generated: {ts}\n")
        w.write(f"Roots: {', '.join(os.path.abspath(r) for r in roots)}\n")
        w.write(f"Files count: {len(files)}\n")
        w.write("\n## Table of Contents\n")
        for i, p in enumerate(files, 1):
            anchor = f"{i}-{p.replace('/','-')}"
            w.write(f"{i}. {p}  ->  #{anchor}\n")
        w.write("\n---\n")

        for i, p in enumerate(files, 1):
            try:
                size = os.path.getsize(p)
                sha  = sha256_of_file(p)
                with open(p,'r',encoding='utf-8',errors='replace') as r:
                    data = r.read()
            except Exception as e:
                data = f"<<error reading {p}: {e}>>"
                size = -1
                sha  = "n/a"

            header = f"\n## {i}. {p}\n#size={size} bytes  sha256={sha}\n<a name=\"{i}-{p.replace('/','-')}\"></a>\n\n"
            body   = "```text\n" + data + "\n```\n"
            chunk  = header + body
            enc    = chunk.encode('utf-8', errors='replace')
            if total_written + len(enc) > MAX_TOTAL_BYTES:
                w.write("\n\n<< STOPPED: reached MAX_TOTAL_BYTES limit >>\n")
                break
            w.write(chunk)
            total_written += len(enc)

    print(f"[ok] Wrote snapshot to: {output}")
    print(f"[info] Files included: {len(files)}")
    print(f"[info] Approx bytes written: {total_written}")

if __name__ == '__main__':
    main()
```

### `tools/./load_healthz.sh`

```
#!/usr/bin/env bash
# load_healthz.sh — прогон healthz с прогрессом
# Usage: ./load_healthz.sh <TOTAL=50000> <CONC=200> <MODE=rr|lb>
set -euo pipefail
TOTAL="${1:-50000}"
CONC="${2:-200}"
MODE="${3:-rr}"

start_ts=$(date +%s%3N)
cnt=0
print_prog() { cnt=$((cnt+1)); if (( cnt % 1000 == 0 )); then echo -n "."; fi; }

if [ "$MODE" = "rr" ]; then
  seq 1 "$TOTAL" | xargs -n1 -P"$CONC" -I{} bash -c '
    i="{}"; r=$(( i % 3 ))
    if   [ $r -eq 0 ]; then p=8080
    elif [ $r -eq 1 ]; then p=8082
    else                   p=8084
    fi
    curl -sS --max-time 2 -o /dev/null "http://127.0.0.1:${p}/healthz"
  ' && echo
else
  seq 1 "$TOTAL" | xargs -n1 -P"$CONC" -I{} bash -c '
    curl -sS --max-time 2 -o /dev/null "http://127.0.0.1/api/healthz"
  ' && echo
fi

end_ts=$(date +%s%3N)
dt_ms=$(( end_ts - start_ts ))
rps=$(( TOTAL * 1000 / (dt_ms>0?dt_ms:1) ))
echo "[OK] sent ${TOTAL} requests in ${dt_ms} ms  → ~${rps} req/s"
```

### `tools/./lrb_audit.sh`

```
#!/usr/bin/env bash
set -euo pipefail
cd /root/logos_lrb

REPORT="AUDIT_REPORT.md"
echo "# LOGOS LRB — Аудит модулей" > "$REPORT"
echo "_$(date -u)_ UTC" >> "$REPORT"
echo >> "$REPORT"

sha() { sha256sum "$1" | awk '{print $1}'; }

audit_rust() {
  local f="$1"
  local lines; lines=$(wc -l <"$f")
  local s_unsafe s_unwrap s_expect s_panic s_todo s_dbg
  s_unsafe=$(grep -c '\<unsafe\>' "$f" || true)
  s_unwrap=$(grep -c 'unwrap(' "$f" || true)
  s_expect=$(grep -c 'expect(' "$f" || true)
  s_panic=$(grep -c 'panic!(' "$f" || true)
  s_dbg=$(grep -Ec 'dbg!|println!' "$f" || true)
  s_todo=$(grep -ni 'TODO\|FIXME\|todo!\|unimplemented!' "$f" | sed 's/^/    /' || true)
  {
    echo "### \`$f\` (Rust)"
    echo "- lines: $lines | sha256: \`$(sha "$f")\`"
    echo "- red-flags: unsafe=$s_unsafe, unwrap=$s_unwrap, expect=$s_expect, panic=$s_panic, dbg/println=$s_dbg"
    [ -n "$s_todo" ] && echo "- TODO/FIXME:"$'\n'"$s_todo"
    echo
  } >> "$REPORT"
}

audit_py() {
  local f="$1"
  local lines; lines=$(wc -l <"$f")
  local s_eval s_exec s_pickle s_subp s_todo
  s_eval=$(grep -c '\<eval\>' "$f" || true)
  s_exec=$(grep -c '\<exec\>' "$f" || true)
  s_pickle=$(grep -c 'pickle' "$f" || true)
  s_subp=$(grep -c 'subprocess' "$f" || true)
  s_todo=$(grep -ni 'TODO\|FIXME' "$f" | sed 's/^/    /' || true)
  {
    echo "### \`$f\` (Python)"
    echo "- lines: $lines | sha256: \`$(sha "$f")\`"
    echo "- red-flags: eval=$s_eval, exec=$s_exec, pickle=$s_pickle, subprocess=$s_subp"
    [ -n "$s_todo" ] && echo "- TODO/FIXME:"$'\n'"$s_todo"
    echo
  } >> "$REPORT"
}

audit_other() {
  local f="$1"
  local lines; lines=$(wc -l <"$f")
  {
    echo "### \`$f\`"
    echo "- lines: $lines | sha256: \`$(sha "$f")\`"
    grep -ni 'TODO\|FIXME' "$f" | sed 's/^/    - /' || true
    echo
  } >> "$REPORT"
}

echo "## Files in modules/" >> "$REPORT"
find modules -maxdepth 1 -type f | sort | while read -r f; do
  case "$f" in
    *.rs) audit_rust "$f" ;;
    *.py) audit_py "$f" ;;
    *.tsx|*.ts|*.yaml|*.yml|*.md) audit_other "$f" ;;
    *) audit_other "$f" ;;
  esac
done
echo >> "$REPORT"

echo "## Files in core/" >> "$REPORT"
find core -maxdepth 1 -type f | sort | while read -r f; do
  case "$f" in
    *.rs) audit_rust "$f" ;;
    *.py) audit_py "$f" ;;
    *.yaml|*.yml|*.md|*.toml) audit_other "$f" ;;
    *) audit_other "$f" ;;
  esac
done
echo >> "$REPORT"

echo "## Quick checks" >> "$REPORT"
{
  echo '```'
  cargo --version 2>/dev/null || true
  python3 --version 2>/dev/null || true
  echo '```'
  echo
} >> "$REPORT"

if [ -f Cargo.toml ]; then
  echo "### cargo check" >> "$REPORT"
  ( cargo check 2>&1 || true ) | sed 's/^/    /' >> "$REPORT"
  echo >> "$REPORT"
fi

# Python syntax check
: > py_err.log || true
find core modules -name '*.py' -print0 | xargs -0 -I{} sh -c 'python3 -m py_compile "{}" 2>>py_err.log' || true
if [ -s py_err.log ]; then
  echo "### python syntax errors" >> "$REPORT"
  sed 's/^/    /' py_err.log >> "$REPORT"
  echo >> "$REPORT"
fi

echo "Done -> $REPORT"
```

### `tools/./make_book_and_push.sh`

```
#!/usr/bin/env bash
set -euo pipefail

ROOT="/root/logos_lrb"
BOOK="$ROOT/docs/LOGOS_LRB_FULL_BOOK.md"
DATE="$(date -Iseconds)"
BRANCH="main"   # пушим прямо в main

lang_by_ext() {
  case "${1##*.}" in
    rs) echo rust;; toml) echo toml;; json) echo json;;
    yml|yaml) echo yaml;; sh|bash) echo bash;; service|timer) echo ini;;
    conf) echo nginx;; html) echo html;; js) echo javascript;;
    css) echo css;; sql) echo sql;; *) echo text;;
  esac
}

# Чистим секреты/домены ТОЛЬКО в выводе (исходники на диске не трогаем)
redact() {
  sed -E \
    -e 's/(LRB_JWT_SECRET[=: ]+)[^" \n]+/\1CHANGE_ME/g' \
    -e 's/(LRB_BRIDGE_KEY[=: ]+)[^" \n]+/\1CHANGE_ME/g' \
    -e 's/(X-Admin-Key: )[^\n"]+/\1CHANGE_ME/g' \
    -e 's/(X-Admin-JWT: )[^\n"]+/\1<ADMIN_JWT>/g' \
    -e 's#(/etc/letsencrypt/live/)[^/]+/#\1<YOUR_DOMAIN>/#g'
}

add()  { printf "%s" "$1" >> "$BOOK"; }
addh() { printf "\n\n---\n\n# %s\n\n" "$1" >> "$BOOK"; }

add_file() {
  local path="$1" lang; lang="$(lang_by_ext "$path")"
  printf "\n\n=== %s ===\n\n" "$path" >> "$BOOK"
  printf '```%s\n' "$lang" >> "$BOOK"
  if [[ -r "$path" ]]; then cat "$path" | redact >> "$BOOK"; else echo "# file not found: $path" >> "$BOOK"; fi
  printf '\n```\n' >> "$BOOK"
}

add_cmd() {
  local title="$1"; shift
  printf "\n\n=== %s ===\n\n" "$title" >> "$BOOK"
  printf '```text\n' >> "$BOOK"
  ( "$@" || true ) | redact >> "$BOOK"
  printf '\n```\n' >> "$BOOK"
}

# ──────────────────────────────────────────────
# Раздел 2: версии и окружение
addh "2. Версии и окружение"
add_cmd "rustc --version" bash -lc "rustc --version"
add_cmd "cargo --version" bash -lc "cargo --version"
add_cmd "nginx -v"       bash -lc "nginx -v 2>&1"
add_cmd "psql --version" bash -lc "psql --version 2>&1 || true"
add_cmd "systemd env"    bash -lc "systemctl show -p Environment logos-node | tr ' ' '\n'"

# ──────────────────────────────────────────────
# Раздел 3: Cargo workspace
addh "3. Cargo workspace"
add_file "$ROOT/Cargo.toml"

# ──────────────────────────────────────────────
# Раздел 4: lrb_core (исходники + Cargo)
addh "4. lrb_core (исходники + Cargo)"
while IFS= read -r f; do add_file "$f"; done \
  < <(find "$ROOT/lrb_core" -type f \( -name '*.rs' -o -name 'Cargo.toml' \) | sort)

# ──────────────────────────────────────────────
# Раздел 5: node (исходники + Cargo)
addh "5. node (исходники + Cargo)"
while IFS= read -r f; do add_file "$f"; done \
  < <(find "$ROOT/node" -type f \( -name '*.rs' -o -name 'Cargo.toml' \) | sort)

# ──────────────────────────────────────────────
# Раздел 6: Web Wallet (index.html/css/js/manifest/sw)
addh "6. Web Wallet"
while IFS= read -r f; do add_file "$f"; done \
  < <(find "$ROOT/www/wallet" -maxdepth 1 -type f \( -name '*.html' -o -name '*.css' -o -name '*.js' -o -name 'manifest.json' -o -name 'sw.js' \) | sort)

# ──────────────────────────────────────────────
# Раздел 7: Explorer
addh "7. Explorer"
while IFS= read -r f; do add_file "$f"; done \
  < <(find "$ROOT/www/explorer" -maxdepth 1 -type f -name '*.html' | sort)

# ──────────────────────────────────────────────
# Раздел 8: Nginx конфиги
addh "8. Nginx конфиги"
while IFS= read -r f; do add_file "$f"; done \
  < <(find /etc/nginx/conf.d -maxdepth 1 -type f -name '*.conf' | sort)

# ──────────────────────────────────────────────
# Раздел 9: Systemd (unit + drop-ins)
addh "9. Systemd (unit + drop-ins)"
add_cmd "systemctl cat logos-node" bash -lc "systemctl cat logos-node"
while IFS= read -r f; do add_file "$f"; done \
  < <(find /etc/systemd/system/logos-node.service.d -maxdepth 1 -type f | sort)

# ──────────────────────────────────────────────
# Раздел 10: Бэкап sled (скрипт/сервис/таймер)
addh "10. Бэкап sled"
[[ -f "/usr/local/bin/logos-sled-backup.sh" ]]          && add_file "/usr/local/bin/logos-sled-backup.sh"
[[ -f "/etc/systemd/system/logos-sled-backup.service" ]]&& add_file "/etc/systemd/system/logos-sled-backup.service"
[[ -f "/etc/systemd/system/logos-sled-backup.timer"   ]]&& add_file "/etc/systemd/system/logos-sled-backup.timer"

# ──────────────────────────────────────────────
# Раздел 11: Prometheus/Grafana (alerts)
addh "11. Prometheus/Grafana (alerts)"
[[ -f "/etc/prometheus/rules/logos_alerts.yml" ]] && add_file "/etc/prometheus/rules/logos_alerts.yml"

# ──────────────────────────────────────────────
# Раздел 12: Конфиги (genesis/logos_config)
addh "12. Конфиги"
[[ -f "$ROOT/configs/genesis.yaml"      ]] && add_file "$ROOT/configs/genesis.yaml"
[[ -f "$ROOT/configs/logos_config.yaml" ]] && add_file "$ROOT/configs/logos_config.yaml"

# ──────────────────────────────────────────────
# Раздел 13: OpenAPI контракт (снимаем у живой ноды)
addh "13. OpenAPI контракт"
add_cmd "GET /openapi.json" bash -lc "curl -s http://127.0.0.1:8080/openapi.json || true"

# ──────────────────────────────────────────────
# Раздел 14: Bootstrap на новом сервере (шаги)
addh "14. Bootstrap на новом сервере (шаги)"
add '
### Ubuntu 22.04/24.04 (root)
```bash
apt update && apt install -y curl git jq build-essential pkg-config libssl-dev \
  nginx postgresql postgresql-contrib rsync

# Rust
curl --proto "=https" --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
. $HOME/.cargo/env

# Клонируем проект
git clone https://github.com/Lgn-rsp/logos_lrb.git /root/logos_lrb
cd /root/logos_lrb

# По канону вставляем файлы из этой книги (см. главы 3–13):
# cd → rm -f → nano → вставить контент блока === <path> === → сохранить

# Systemd drop-ins — ЗАМЕНИТЬ CHANGE_ME на реальные секреты
sudo mkdir -p /etc/systemd/system/logos-node.service.d
sudo tee /etc/systemd/system/logos-node.service.d/zz-secrets-inline.conf >/dev/null <<EOF
[Service]
Environment=LRB_JWT_SECRET=CHANGE_ME
Environment=LRB_BRIDGE_KEY=CHANGE_ME
EOF
sudo tee /etc/systemd/system/logos-node.service.d/paths.conf >/dev/null <<EOF
[Service]
Environment=LRB_DATA_PATH=/var/lib/logos/data.sled
Environment=LRB_NODE_KEY_PATH=/var/lib/logos/node_key
EOF
sudo systemctl daemon-reload

# Сборка/деплой
cargo build --release -p logos_node
install -m 0755 target/release/logos_node /opt/logos/bin/logos_node
sudo chown logos:logos /opt/logos/bin/logos_node
sudo systemctl restart logos-node
sleep 1
curl -s http://127.0.0.1:8080/healthz; echo
curl -s http://127.0.0.1:8080/head; echo

# Nginx
nginx -t && systemctl reload nginx
```'

# ──────────────────────────────────────────────
# Раздел 15: Канон проверки
addh "15. Канон проверки"
add '
```bash
journalctl -u logos-node -n 120 --no-pager | egrep -i "listening|panic|error" || true
curl -s http://127.0.0.1:8080/healthz; echo
curl -s http://127.0.0.1:8080/head; echo
curl -s http://127.0.0.1:8080/economy | jq
curl -s "http://127.0.0.1:8080/archive/blocks?limit=3" | jq
curl -s "http://127.0.0.1:8080/archive/txs?limit=3"    | jq
```'

# ──────────────────────────────────────────────
# Автопуш книги в GitHub (ветка main, репо Lgn-rsp/logos_lrb)
cd "$ROOT"

# если это ещё не репозиторий — подсказываем
if ! git rev-parse --is-inside-work-tree >/dev/null 2>&1; then
  echo "NOTE: git repo not found."
  echo "Run once:"
  echo "  git init"
  echo "  git remote add origin https://github.com/Lgn-rsp/logos_lrb.git"
  echo "  git fetch origin"
fi

# конфиг git
git config user.name  >/dev/null 2>&1 || git config --global user.name "LOGOS Ops"
git config user.email >/dev/null 2>&1 || git config --global user.email "ops@logos.local"

# добавляем книгу и скрипт
git add docs/LOGOS_LRB_FULL_BOOK.md tools/make_book_and_push.sh || true
git commit -m "docs: full system book ($DATE)" || true

# пуш в main
git push -u origin main || true

# финальный маркер
echo -e "\n\n---\n\n# Конец книги\n" >> "$BOOK"
```

### `tools/./make_codebook.sh`

```
#!/usr/bin/env sh
# LOGOS LRB — FULL LIVE book: repo + infra в один TXT (с маскировкой секретов)
set -eu

ROOT="$(cd "$(dirname "$0")/.."; pwd)"
OUT_DIR="docs"
STAMP="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
OUT_FILE_TMP="${OUT_DIR}/LRB_FULL_LIVE_${STAMP}.txt.tmp"
OUT_FILE="${OUT_DIR}/LRB_FULL_LIVE_${STAMP}.txt"
SIZE_LIMIT="${SIZE_LIMIT:-2000000}"   # 2 MB per file
REPO_ROOT="/root/logos_lrb"

# --- ВКЛЮЧАЕМ ИЗ РЕПО ---
REPO_GLOBS='
Cargo.toml
README.md
src
lrb_core/src
node/src
modules
core
wallet-proxy
docs
www/wallet
www/explorer
infra/nginx
infra/systemd
scripts
tools
configs
'

# --- ВКЛЮЧАЕМ ИНФРУ С СЕРВЕРА ---
INFRA_FILES='
/etc/nginx/nginx.conf
/etc/nginx/conf.d/*.conf
/etc/nginx/sites-enabled/*
/etc/systemd/system/logos-node.service
/etc/systemd/system/*.service
/etc/systemd/system/*.timer
/etc/systemd/system/logos-node.service.d/*.conf
/etc/prometheus/prometheus.yml
/etc/prometheus/rules/*.yml
/etc/alertmanager/alertmanager.yml
/etc/alertmanager/secrets.env
/etc/grafana/grafana.ini
/etc/grafana/provisioning/datasources/*.yaml
/etc/grafana/provisioning/dashboards/*.yaml
/var/lib/grafana/dashboards/*.json
/opt/logos/www/wallet/*
/opt/logos/www/explorer/*
'

# --- ИСКЛЮЧЕНИЯ ДЛЯ РЕПО ---
EXCLUDES_REPO='
.git
target
node_modules
venv
__pycache__
*.pyc
data.sled
var
*.log
*.pem
*.der
*.crt
*.key
*.zip
*.tar
*.tar.gz
*.7z
LOGOS_LRB_FULL_BOOK.md
'

# язык для подсветки
lang_for() {
  case "${1##*.}" in
    rs) echo "rust" ;; toml) echo "toml" ;; json) echo "json" ;;
    yml|yaml) echo "yaml" ;; sh|bash) echo "bash" ;; py) echo "python" ;;
    js) echo "javascript" ;; ts) echo "typescript" ;; tsx|jsx) echo "tsx" ;;
    html|htm) echo "html" ;; css) echo "css" ;; md) echo "markdown" ;;
    conf|ini|service|timer|env) echo "" ;; *) echo "" ;;
  esac
}

# доверяем расширению, иначе grep -Iq
looks_text() {
  case "$1" in
    *.rs|*.toml|*.json|*.yml|*.yaml|*.sh|*.bash|*.py|*.js|*.ts|*.tsx|*.jsx|*.html|*.htm|*.css|*.md|*.conf|*.ini|*.service|*.timer|*.env) return 0;;
    *) LC_ALL=C grep -Iq . "$1";;
  esac
}

# фильтр исключений репо
should_exclude_repo() {
  f="$1"
  # с двоеточиями — мусор от редакторов
  echo "$f" | grep -q ":" && return 0
  echo "$EXCLUDES_REPO" | while IFS= read -r pat; do
    [ -z "$pat" ] && continue
    [ "${pat#\#}" != "$pat" ] && continue
    case "$f" in */$pat/*|*/$pat|$pat) exit 0;; esac
  done; return 1
}

# маска секретов
mask_secrets() {
  sed -E \
    -e 's/(TELEGRAM_BOT_TOKEN=)[A-Za-z0-9:_-]+/\1***MASKED***/g' \
    -e 's/(TELEGRAM_CHAT_ID=)[0-9-]+/\1***MASKED***/g' \
    -e 's/(LRB_ADMIN_KEY=)[A-Fa-f0-9]+/\1***MASKED***/g' \
    -e 's/(LRB_BRIDGE_KEY=)[A-Fa-f0-9]+/\1***MASKED***/g' \
    -e 's/(LRB_ADMIN_JWT_SECRET=)[A-Za-z0-9._-]+/\1***MASKED***/g'
}

write_header() {
  {
    echo "# FULL LIVE SNAPSHOT — $(date -u +%Y-%m-%dT%H:%M:%SZ)"
    echo "# sources: $REPO_ROOT + infra (/etc, /opt)"
    echo "# size limit per file: ${SIZE_LIMIT} bytes"
    echo
  } >>"$OUT_FILE_TMP"
}

dump_file() {
  f="$1"
  [ -f "$f" ] || return 0
  echo "$f" | grep -q ":" && return 0     # отсекаем мусорные имена

  sz="$(wc -c <"$f" | tr -d ' ' || echo 0)"
  [ "$sz" -eq 0 ] && { printf "\n## FILE: %s  (SKIPPED, empty)\n" "$f" >>"$OUT_FILE_TMP"; return 0; }
  [ "$sz" -gt "$SIZE_LIMIT" ] && { printf "\n## FILE: %s  (SKIPPED, size=%sb > limit)\n" "$f" "$sz" >>"$OUT_FILE_TMP"; return 0; }

  printf "\n## FILE: %s  (size=%sb)\n" "$f" "$sz" >>"$OUT_FILE_TMP"
  if looks_text "$f"; then
    printf '```\n' >>"$OUT_FILE_TMP"
    case "$f" in
      */alertmanager/secrets.env|*/logos-node.service.d/*|*/nginx/*.conf|*/conf.d/*.conf|*/sites-enabled/*|*/prometheus*.yml|*/grafana/*.ini|*/provisioning/*|*/dashboards/*.json)
        mask_secrets < "$f" >>"$OUT_FILE_TMP" ;;
      *) cat "$f" >>"$OUT_FILE_TMP" ;;
    esac
    printf '\n```\n' >>"$OUT_FILE_TMP"
  else
    printf "\n(SKIPPED, binary/non-text)\n" >>"$OUT_FILE_TMP"
  fi
}

collect_repo() {
  echo "$REPO_GLOBS" | while IFS= read -r rel; do
    [ -z "$rel" ] && continue
    [ "${rel#\#}" != "$rel" ] && continue
    p="$REPO_ROOT/$rel"
    if [ -d "$p" ]; then find "$p" -type f; elif [ -f "$p" ]; then echo "$p"; fi
  done
}

collect_infra() {
  echo "$INFRA_FILES" | while IFS= read -r pat; do
    [ -z "$pat" ] && continue
    [ "${pat#\#}" != "$pat" ] && continue
    for f in $pat; do [ -f "$f" ] && echo "$f"; done
  done
}

main() {
  mkdir -p "$OUT_DIR"
  : >"$OUT_FILE_TMP"
  write_header

  collect_repo  | sort -u | while IFS= read -r p; do
    if should_exclude_repo "$p"; then continue; fi
    dump_file "$p"
  done

  collect_infra | sort -u | while IFS= read -r p; do
    dump_file "$p"
  done

  mv -f "$OUT_FILE_TMP" "$OUT_FILE"
  echo "✅ created: $OUT_FILE"
  cp -f "$OUT_FILE" "${ROOT}/LOGOS_LRB_FULL_BOOK.md" 2>/dev/null || true
}

main "$@"
```

### `tools/./make_full_book.sh`

```
#!/usr/bin/env bash
# LOGOS LRB — Полная книга: исходники из репозитория + ключевые прод-конфиги
set -euo pipefail

ROOT="$(cd "$(dirname "$0")/.."; pwd)"
OUT="${ROOT}/LOGOS_LRB_FULL_BOOK.md"
TS="$(date -u +'%Y-%m-%d %H:%M:%S UTC')"
GIT_SHA="$(git -C "$ROOT" rev-parse --short=7 HEAD 2>/dev/null || echo 'no-git')"

# ---------- Параметры ----------
# исключаем мусор/бинарь/секреты
EXCLUDES_REPO=(
  ".git" "target" "node_modules" "venv" "__pycache__" "data.sled" "var"
  "LOGOS_LRB_FULL_BOOK.md" "*.log" "*.pem" "*.der" "*.crt" "*.key" "*.zip" "*.tar" "*.tar.gz" "*.7z"
)
# включаем infra из whitelist-путей
INFRA_FILES=(
  "/etc/nginx/conf.d/*.conf"
  "/etc/systemd/system/logos-node.service"
  "/etc/systemd/system/logos-node.service.d/*.conf"
  "/etc/prometheus/prometheus.yml"
  "/etc/prometheus/rules/*.yml"
  "/etc/alertmanager/alertmanager.yml"
  "/etc/alertmanager/secrets.env"
  "/etc/grafana/provisioning/datasources/*.yaml"
  "/etc/grafana/provisioning/dashboards/*.yaml"
  "/var/lib/grafana/dashboards/*.json"
)
MAX_SIZE=$((2*1024*1024))  # 2 МБ на файл

lang_for() {
  case "${1##*.}" in
    rs) echo "rust" ;; toml) echo "toml" ;; json) echo "json" ;;
    yml|yaml) echo "yaml" ;; sh|bash) echo "bash" ;; py) echo "python" ;;
    js) echo "javascript" ;; ts) echo "typescript" ;; tsx|jsx) echo "tsx" ;;
    html|htm) echo "html" ;; css) echo "css" ;; md) echo "markdown" ;;
    conf|ini|service|timer) echo "" ;;  *) echo "" ;;
  esac
}

exclude_match() {
  local f="$1"
  for p in "${EXCLUDES_REPO[@]}"; do
    case "$p" in
      *"*") [[ "$f" == $p ]] && return 0 ;;
      *)    [[ "$f" == */$p/* || "$f" == */$p || "$f" == $p ]] && return 0 ;;
    esac
  done
  return 1
}

# маскировка секретов для infra (телеграм токены, и т.п.)
mask_infra() {
  # stdin -> stdout
  sed -E \
    -e 's/(TELEGRAM_BOT_TOKEN=)[A-Za-z0-9:_-]+/\1***MASKED*** /g' \
    -e 's/(TELEGRAM_CHAT_ID=)[0-9-]+/\1***MASKED*** /g'
}

# ---------- Заголовок ----------
{
  echo "# LOGOS LRB — Полная книга (исходники + прод-конфиги)"
  echo
  echo "_Generated: ${TS} • Commit: ${GIT_SHA}_"
  echo
  echo "> В книге: весь код из репозитория + основные конфиги из /etc. Исключены бинарные/ключевые файлы; секреты замаскированы."
  echo
  echo "## Оглавление"
} > "$OUT"

TMP_LIST="$(mktemp)"
( cd "$ROOT" && find . -type f -print0 ) >"$TMP_LIST"

# ---------- Оглавление: репозиторий ----------
while IFS= read -r -d '' f; do
  exclude_match "$f" && continue
  sz=$(stat -c%s "$ROOT/$f" 2>/dev/null || echo 0)
  (( sz > MAX_SIZE )) && continue
  anchor="$(echo "repo-$f" | sed 's/^\.\///' | tr '/.' '--' | tr -cd '[:alnum:]-_' | tr '[:upper:]' '[:lower:]')"
  echo "- [repo:$f](#$anchor)" >> "$OUT"
done < "$TMP_LIST"

# ---------- Оглавление: infra ----------
for pat in "${INFRA_FILES[@]}"; do
  for f in $pat; do
    [[ -f "$f" ]] || continue
    sz=$(stat -c%s "$f" 2>/dev/null || echo 0)
    (( sz > MAX_SIZE )) && continue
    anchor="$(echo "infra-$f" | sed 's#/##g;s#:#-#g' | tr -cd '[:alnum:]-_' | tr '[:upper:]' '[:lower:]')"
    echo "- [infra:$f](#$anchor)" >> "$OUT"
  done
done

{
  echo
  echo "---"
  echo
  echo "## Раздел I. Исходники репозитория"
  echo
} >> "$OUT"

# ---------- Контент: репозиторий ----------
while IFS= read -r -d '' f; do
  exclude_match "$f" && continue
  sz=$(stat -c%s "$ROOT/$f" 2>/dev/null || echo 0)
  (( sz > MAX_SIZE )) && { echo "skip big: $f" >&2; continue; }
  rel="${f#./}"
  anchor="$(echo "repo-$f" | sed 's/^\.\///' | tr '/.' '--' | tr -cd '[:alnum:]-_' | tr '[:upper:]' '[:lower:]')"
  lang="$(lang_for "$rel")"
  {
    echo "### $rel"
    echo "<a id=\"$anchor\"></a>"
    echo
    echo '```'"$lang"
    cat "$ROOT/$f"
    echo
    echo '```'
    echo
  } >> "$OUT"
done < "$TMP_LIST"

rm -f "$TMP_LIST"

# ---------- Контент: infra ----------
{
  echo
  echo "## Раздел II. Инфраструктурные конфиги (прод)"
  echo
} >> "$OUT"

for pat in "${INFRA_FILES[@]}"; do
  for f in $pat; do
    [[ -f "$f" ]] || continue
    sz=$(stat -c%s "$f" 2>/dev/null || echo 0)
    (( sz > MAX_SIZE )) && { echo "skip big: $f" >&2; continue; }
    anchor="$(echo "infra-$f" | sed 's#/##g;s#:#-#g' | tr -cd '[:alnum:]-_' | tr '[:upper:]' '[:lower:]')"
    lang="$(lang_for "$f")"
    {
      echo "### $f"
      echo "<a id=\"$anchor\"></a>"
      echo
      echo '```'"$lang"
      # маскируем секреты в alertmanager/secrets.env и похожем
      case "$f" in
        */alertmanager/secrets.env) mask_infra < "$f" ;;
        *) cat "$f" ;;
      esac
      echo
      echo '```'
      echo
    } >> "$OUT"
  done
done

echo "✅ Сформировано: $OUT"
```

### `tools/./make_full_snapshot_live.sh`

```
#!/usr/bin/env bash
set -euo pipefail

OUTDIR="${OUTDIR:-/root/logos_snapshot}"
STAMP=$(date +%Y%m%d_%H%M)
OUT="$OUTDIR/LRB_FULL_LIVE_${STAMP}.txt"
MAX=${MAX:-800000}  # макс размер включаемого файла (байт)

mkdir -p "$OUTDIR"

say(){ echo "$@" >&2; }
add_head(){
  echo -e "\n\n## FILE: $1  (size=${2}b)\n\`\`\`" >> "$OUT"
}
add_tail(){
  echo -e "\n\`\`\`" >> "$OUT"
}

# Источники (живые пути)
SRC_LIST=(
  "/root/logos_lrb"                   # весь код репо
  "/opt/logos/www/wallet"             # кошелёк
  "/etc/systemd/system/logos-node@.service"
  "/etc/systemd/system/logos-healthcheck.service"
  "/etc/systemd/system/logos-healthcheck.timer"
  "/etc/nginx/sites-available/logos-api-lb.conf"
  "/usr/local/bin/logos_healthcheck.sh"
)

# Заголовок
{
  echo "# FULL LIVE SNAPSHOT — $(date -u +%FT%TZ)"
  echo "# sources:"
  for s in "${SRC_LIST[@]}"; do echo "#  - $s"; done
  echo "# size limit per file: ${MAX} bytes"
  echo
} > "$OUT"

# Вспомогательные функции
is_text(){
  # бинарники/картинки отсекаем простым тестом: попытка вывести «без нулевых байтов»
  # или используем file(1) если есть
  if command -v file >/dev/null 2>&1; then
    file -b --mime "$1" | grep -qiE 'text|json|xml|yaml|toml|javascript|html|css' && return 0 || return 1
  else
    grep -Iq . "$1" && return 0 || return 1
  fi
}

emit_file(){
  local f="$1"
  [ -f "$f" ] || return 0
  # исключения
  case "$f" in
    *.pem|*.key|*.crt|*.p12|*.so|*.bin|*.png|*.jpg|*.jpeg|*.gif|*.svg|*.woff|*.woff2|*.ttf) return 0;;
  esac
  local sz
  sz=$(stat -c%s "$f" 2>/dev/null || echo 0)
  if [ "$sz" -gt "$MAX" ]; then
    echo -e "\n\n## FILE: $f  (SKIPPED, size=${sz}b > ${MAX})" >> "$OUT"
    return 0
  fi
  if ! is_text "$f"; then
    echo -e "\n\n## FILE: $f  (SKIPPED, binary/non-text size=${sz}b)" >> "$OUT"
    return 0
  fi
  add_head "$f" "$sz"
  sed -e 's/\r$//' "$f" >> "$OUT"
  add_tail
}

# 1) Репозиторий: только текстовые файлы, игнорим target/node_modules/dist
if [ -d /root/logos_lrb ]; then
  say "[*] collecting /root/logos_lrb"
  cd /root/logos_lrb
  # берём отслеживаемые git'ом; если git недоступен — найдём все текстовые расширения
  if git rev-parse --is-inside-work-tree >/dev/null 2>&1; then
    git ls-files | while read -r f; do
      case "$f" in target/*|**/target/*|node_modules/*|dist/*) continue;; esac
      emit_file "/root/logos_lrb/$f"
    done
  else
    find . -type f ! -path "./target/*" ! -path "./node_modules/*" ! -path "./dist/*" \
      -regextype posix-extended -regex '.*\.(rs|toml|md|sh|bash|zsh|service|timer|conf|nginx|yaml|yml|json|ts|tsx|js|mjs|jsx|html|htm|css|go|py|proto|ini|cfg|txt)$' \
      -print0 | xargs -0 -I{} bash -c 'emit_file "{}"'
  fi
  cd - >/dev/null
fi

# 2) Статика кошелька
if [ -d /opt/logos/www/wallet ]; then
  say "[*] collecting /opt/logos/www/wallet"
  find /opt/logos/www/wallet -type f -print0 | while IFS= read -r -d '' f; do emit_file "$f"; done
fi

# 3) systemd units
for u in /etc/systemd/system/logos-node@.service /etc/systemd/system/logos-healthcheck.service /etc/systemd/system/logos-healthcheck.timer; do
  [ -f "$u" ] && emit_file "$u"
done

# 4) nginx site
[ -f /etc/nginx/sites-available/logos-api-lb.conf ] && emit_file /etc/nginx/sites-available/logos-api-lb.conf

# 5) healthcheck script
[ -f /usr/local/bin/logos_healthcheck.sh ] && emit_file /usr/local/bin/logos_healthcheck.sh

# 6) Живые .env → в слепок как обезличенные *.example
sanitize_env(){
  sed -E \
    -e 's/^(LRB_NODE_SK_HEX)=.*/\1=CHANGE_ME_64_HEX/' \
    -e 's/^(LRB_ADMIN_KEY)=.*/\1=CHANGE_ADMIN_KEY/' \
    -e 's/^(LRB_BRIDGE_KEY)=.*/\1=CHANGE_ME/' \
    -e 's/^(HOT_WALLET_PRIVATE_KEY)=.*/\1=CHANGE_ME/' \
    -e 's/^(TG_TOKEN)=.*/\1=CHANGE_ME/' \
    -e 's/^(TG_CHAT_ID)=.*/\1=CHANGE_ME/' \
    "$1"
}
if ls /etc/logos/node-*.env >/dev/null 2>&1; then
  for f in /etc/logos/node-*.env; do
    tmp="$(mktemp)"; sanitize_env "$f" > "$tmp"
    sz=$(stat -c%s "$tmp" 2>/dev/null || echo 0)
    add_head "${f}.example" "$sz"
    cat "$tmp" >> "$OUT"
    add_tail
    rm -f "$tmp"
  done
fi

echo "[ok] wrote $OUT"
```

### `tools/./prepare_payer.sh`

```
#!/usr/bin/env bash
set -euo pipefail

API=${API:-http://127.0.0.1:8080}
FROM=${FROM:-PAYER}
AMOUNT=${AMOUNT:-1000000}
NONCE=${NONCE:-0}

JWT_SECRET="$(sed -n 's/^LRB_ADMIN_JWT_SECRET=//p' /etc/logos/keys.env | tr -d '[:space:]')"
if [[ -z "${JWT_SECRET}" ]]; then
  echo "[ERR] LRB_ADMIN_JWT_SECRET is empty"; exit 1
fi

b64url() { openssl base64 -A | tr '+/' '-_' | tr -d '='; }

H=$(printf '{"alg":"HS256","typ":"JWT"}' | b64url)
P=$(printf '{"sub":"admin","iat":1690000000,"exp":2690000000}' | b64url)
S=$(printf '%s' "$H.$P" | openssl dgst -sha256 -hmac "$JWT_SECRET" -binary | b64url)
JWT="$H.$P.$S"

echo "[*] set_balance $FROM = $AMOUNT"
curl -sf -X POST "$API/admin/set_balance" \
  -H "X-Admin-JWT: $JWT" -H 'Content-Type: application/json' \
  -d "{\"rid\":\"$FROM\",\"amount\":$AMOUNT}" || { echo; echo "[ERR] set_balance failed"; exit 1; }
echo

echo "[*] set_nonce $FROM = $NONCE"
curl -sf -X POST "$API/admin/set_nonce" \
  -H "X-Admin-JWT: $JWT" -H 'Content-Type: application/json' \
  -d "{\"rid\":\"$FROM\",\"value\":$NONCE}" || { echo; echo "[ERR] set_nonce failed"; exit 1; }
echo

echo "[*] balance:"
curl -sf "$API/balance/$FROM" || true
echo
```

### `tools/./repo_audit.sh`

```
#!/usr/bin/env bash
set -euo pipefail

fail=0
pass(){ printf "  [OK]  %s\n" "$1"; }
err(){  printf "  [FAIL] %s\n" "$1"; fail=1; }

echo "== GIT STATUS =="
git rev-parse --is-inside-work-tree >/dev/null 2>&1 || { echo "not a git repo"; exit 1; }
git status --porcelain

echo "== CORE CODE =="
[ -d lrb_core/src ] && pass "lrb_core/src" || err "lrb_core/src missing"
[ -f lrb_core/src/ledger.rs ] && pass "lrb_core ledger.rs" || err "ledger.rs missing"
[ -f lrb_core/src/rcp_engine.rs ] && pass "lrb_core rcp_engine.rs" || err "rcp_engine.rs missing"
[ -f lrb_core/src/phase_filters.rs ] && pass "lrb_core phase_filters.rs" || err "phase_filters.rs missing"
[ -f lrb_core/src/crypto.rs ] && pass "lrb_core crypto.rs (AEAD)" || err "crypto.rs missing"

echo "== NODE =="
for f in node/src/main.rs node/src/api.rs node/src/metrics.rs node/src/guard.rs node/src/storage.rs node/src/version.rs; do
  [ -f "$f" ] && pass "$f" || err "$f missing"
done
[ -f node/src/openapi.json ] && pass "node/src/openapi.json" || err "openapi.json missing"
[ -f node/build.rs ] && pass "node/build.rs" || err "node/build.rs missing"
[ -f node/Cargo.toml ] && pass "node/Cargo.toml" || err "node/Cargo.toml missing"

echo "== MODULES DIR =="
[ -d modules ] && pass "modules/ present" || err "modules/ missing"

echo "== WALLET =="
for f in www/wallet/index.html www/wallet/wallet.css www/wallet/wallet.js; do
  [ -f "$f" ] && pass "$f" || err "$f missing"
done

echo "== INFRA =="
for f in infra/systemd/logos-node@.service infra/systemd/logos-healthcheck.service infra/systemd/logos-healthcheck.timer \
         infra/nginx/logos-api-lb.conf.example; do
  [ -f "$f" ] && pass "$f" || err "$f missing"
done

echo "== SCRIPTS =="
[ -f scripts/bootstrap_node.sh ] && pass "scripts/bootstrap_node.sh" || err "bootstrap_node.sh missing"
[ -f scripts/logos_healthcheck.sh ] && pass "scripts/logos_healthcheck.sh" || err "logos_healthcheck.sh missing"

echo "== TOOLS =="
[ -f tools/bench/go/bench.go ] && pass "bench v4: tools/bench/go/bench.go" || err "bench.go missing"
[ -f tools/sdk/ts/index.mjs ] && pass "TS SDK: tools/sdk/ts/index.mjs" || err "TS SDK missing"
[ -f tools/sdk/ts/sdk_test.mjs ] && pass "TS SDK test" || err "TS SDK test missing"
[ -f tools/sdk/go/logosapi.go ] && pass "Go SDK: tools/sdk/go/logosapi.go" || err "Go SDK missing"

echo "== CONFIGS / EXAMPLES =="
ls -1 configs/env/*.example >/dev/null 2>&1 && pass "env examples present" || err "env examples missing"
# убедимся что реальные .env не попали
if git ls-files | grep -E '^configs/env/.*\.env$' >/dev/null; then
  err "real .env found in repo"
else
  pass "no real .env tracked"
fi

echo "== SNAPSHOTS (optional) =="
[ -d snapshots ] && echo "  [info] snapshots/ exists (ok)"; true

echo "== SIZE / SUMMARY =="
echo "  tracked files: $(git ls-files | wc -l)"
echo "  repo disk size: $(du -sh . | cut -f1)"

echo "== SECRET LEAK SCAN (quick) =="
git grep -nE '(PRIVATE|SECRET|BEGIN (RSA|EC) PRIVATE KEY)' || true
git grep -nE 'LRB_NODE_SK_HEX=[0-9a-fA-F]{64}$' || true

echo
if [ $fail -eq 0 ]; then
  echo "[RESULT] REPO OK"
else
  echo "[RESULT] FAILS PRESENT"; exit 1
fi
```

### `tools/./test_tx.sh`

```
#!/usr/bin/env bash
set -euo pipefail

NODE="${NODE:-http://127.0.0.1:8080}"

echo "[*] Installing deps (jq, pip, pynacl, base58)..."
apt-get update -y >/dev/null 2>&1 || true
apt-get install -y jq python3-pip >/dev/null 2>&1 || true
python3 -m pip install --quiet --no-input pynacl base58

echo "[*] Generating key, RID and signed tx..."
PYOUT="$(python3 - <<'PY'
import json, base64, base58
from nacl.signing import SigningKey

sk = SigningKey.generate()
vk = sk.verify_key
pk = bytes(vk)
rid = base58.b58encode(pk).decode()

amount = 12345
nonce  = 1

msg_obj = {
    "from": rid,
    "to": rid,
    "amount": amount,
    "nonce": nonce,
    "public_key": base64.b64encode(pk).decode()
}
msg = json.dumps(msg_obj, separators=(',',':')).encode()
sig = sk.sign(msg).signature

tx = {
    "from": rid,
    "to": rid,
    "amount": amount,
    "nonce": nonce,
    "public_key_b58": base58.b58encode(pk).decode(),
    "signature_b64": base64.b64encode(sig).decode()
}

print(json.dumps({"rid": rid, "tx": tx}))
PY
)"

RID="$(echo "$PYOUT" | jq -r .rid)"
TX="$(echo "$PYOUT" | jq -c .tx)"

echo "[*] Healthz:"
curl -s "$NODE/healthz" | jq .

echo "[*] Head before:"
curl -s "$NODE/head" | jq .

echo "[*] Submitting tx..."
RESP="$(curl -s -X POST "$NODE/submit_tx" -H 'content-type: application/json' -d "$TX")" || true
echo "$RESP" | jq . || true

# Если узел отклонил (например, nonce/balance), покажем причину и выйдем
if ! echo "$RESP" | jq -e '.accepted == true' >/dev/null 2>&1 ; then
  echo "[!] TX not accepted. Response above."
  exit 1
fi

TXID="$(echo "$RESP" | jq -r .tx_id)"
echo "[*] tx_id=$TXID"

echo "[*] Waiting 2s for block producer..."
sleep 2

echo "[*] Head after:"
curl -s "$NODE/head" | jq .

echo "[*] Balance for RID:"
curl -s "$NODE/balance/$RID" | jq .

echo "[*] Done."
```

### `tools/./tx_load.sh`

```
#!/usr/bin/env bash
# tx_load.sh — надёжная нагрузка через LB/BE без конфликтов nonce.
# Отправка батчей строго по порядку внутри каждого RID (шарда).
# Параллельность — между шардами.
#
# Usage:
#   BACKEND=http://127.0.0.1:8080 ./tx_load.sh M K C [AMOUNT] [SHARDS]
#   (если хочешь через LB: BACKEND=http://127.0.0.1/api)
set -euo pipefail
BACKEND="${BACKEND:-http://127.0.0.1:8080}"   # куда шлём ВСЁ: faucet, canon, submit
M="${1:-1000}"     # всего tx
K="${2:-100}"      # размер батча
C="${3:-10}"       # параллельность шардов (RID)
AMOUNT="${4:-1}"
SHARDS="${5:-$C}"  # число независимых отправителей (RID)

need() { command -v "$1" >/dev/null || { echo "need $1"; exit 1; }; }
need curl; need jq; need openssl; need xxd; need seq; need awk; need sort; need xargs

work="$(mktemp -d -t lrb_load_XXXX)"
trap 'rm -rf "$work"' EXIT
echo "[*] work dir: $work"
per_shard=$(( (M + SHARDS - 1) / SHARDS ))
echo "[*] total=$M  shards=$SHARDS  per_shard≈$per_shard  batch=$K  parallel=$C  amount=$AMOUNT"
echo "[*] BACKEND=$BACKEND"

make_rid() {
  local out="$1"
  openssl genpkey -algorithm Ed25519 -out "$out/ed25519.sk.pem" >/dev/null 2>&1
  openssl pkey -in "$out/ed25519.sk.pem" -pubout -outform DER | tail -c 32 | xxd -p -c 32 > "$out/pk.hex"
  python3 - "$out/pk.hex" > "$out/RID.txt" <<'PY'
import sys
ALPH="123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
pk=bytes.fromhex(open(sys.argv[1]).read().strip())
n=int.from_bytes(pk,'big'); s=""
while n>0: n,r=divmod(n,58); s=ALPH[r]+s
z=0
for b in pk:
    if b==0: z+=1
    else: break
print("1"*z + (s or "1"))
PY
}

# 1) Готовим шардовые каталоги: RID, faucet, nonce0
for s in $(seq 1 "$SHARDS"); do
  sd="$work/shard_$s"; mkdir -p "$sd/batches"
  make_rid "$sd"
  RID=$(cat "$sd/RID.txt")
  echo "[*] shard $s RID=$RID"
  curl -s -X POST "$BACKEND/faucet" -H 'Content-Type: application/json' \
    -d "{\"rid\":\"${RID}\",\"amount\":500000000}" >/dev/null
  NONCE0=$(curl -s "$BACKEND/balance/${RID}" | jq -r .nonce)
  echo "$NONCE0" > "$sd/nonce0"
done

# 2) Генерация подписанных tx для каждого шарда (последовательно → без гонок)
for s in $(seq 1 "$SHARDS"); do
  sd="$work/shard_$s"
  RID=$(cat "$sd/RID.txt")
  SK="$sd/ed25519.sk.pem"
  NONCE0=$(cat "$sd/nonce0")
  start=$(( (s-1)*per_shard + 1 ))
  end=$(( s*per_shard )); [ "$end" -gt "$M" ] && end="$M"
  count=$(( end - start + 1 )); [ "$count" -le 0 ] && continue
  echo "[*] shard $s: tx $start..$end (count=$count)"

  : > "$sd/cur_lines.jsonl"; idx=0; file_lines=0
  for i in $(seq 1 "$count"); do
    nonce=$(( NONCE0 + i ))
    echo "{\"tx\":{\"from\":\"$RID\",\"to\":\"$RID\",\"amount\":$AMOUNT,\"nonce\":$nonce}}" > "$sd/canon_payload.json"
    CANON_HEX=$(curl -s -X POST "$BACKEND/debug_canon" -H "Content-Type: application/json" \
      --data-binary @"$sd/canon_payload.json" | jq -r .canon_hex)
    echo -n "$CANON_HEX" | xxd -r -p > "$sd/canon.bin"
    openssl pkeyutl -sign -rawin -inkey "$SK" -in "$sd/canon.bin" -out "$sd/sig.bin" >/dev/null 2>&1
    SIG_HEX=$(xxd -p -c 256 "$sd/sig.bin")
    printf '{"from":"%s","to":"%s","amount":%s,"nonce":%s,"sig_hex":"%s"}\n' \
      "$RID" "$RID" "$AMOUNT" "$nonce" "$SIG_HEX" >> "$sd/cur_lines.jsonl"
    file_lines=$((file_lines+1))
    if [ "$file_lines" -ge "$K" ]; then
      idx=$((idx+1)); jq -s '{txs:.}' "$sd/cur_lines.jsonl" > "$sd/batches/batch_${s}_$(printf "%05d" $idx).json"
      : > "$sd/cur_lines.jsonl"; file_lines=0
    fi
  done
  if [ "$file_lines" -gt 0 ]; then
    idx=$((idx+1)); jq -s '{txs:.}' "$sd/cur_lines.jsonl" > "$sd/batches/batch_${s}_$(printf "%05d" $idx).json"
  fi
done

# 3) Отправляем батчи ПО ШАРДАМ: внутри каждого — строго по порядку; шарды — параллельно
start_ts=$(date +%s%3N)
ls -1d "$work"/shard_* | xargs -I{} -P"$C" bash -lc '
  sd="{}"
  for f in $(ls -1 "$sd"/batches/batch_*.json | sort -V); do
    curl -s -X POST "'"$BACKEND"'/submit_tx_batch" -H "Content-Type: application/json" \
      --data-binary @"$f" | jq -c "{accepted,rejected,new_height}"
  done
'
end_ts=$(date +%s%3N)
dt=$((end_ts - start_ts))
echo "=== DONE in ${dt} ms → ~ $(( M*1000/(dt>0?dt:1) )) tx/s (client-side est) ==="

# 4) HEAD / METRICS
echo "--- HEAD ---";    curl -s "$BACKEND/head" | jq .
echo "--- METRICS ---"
curl -s "$BACKEND/metrics" \
 | grep -E "lrb_tx_|submit_tx_batch|http_request_duration_seconds_bucket|http_inflight_requests" \
 | head -n 120 || true
```

### `tools/./tx_one.sh`

```
#!/usr/bin/env bash
# tx_one.sh — e2e: генерирует ключ, делает RID, faucet, строит канон, подписывает Ed25519 (raw),
# отправляет /submit_tx_batch и печатает head/balance/метрики.
# Usage: PORT=8080 ./tx_one.sh [AMOUNT]
set -euo pipefail
PORT="${PORT:-8080}"
AMOUNT="${1:-1234}"

work="$(mktemp -d -t lrb_one_XXXX)"
trap 'rm -rf "$work"' EXIT

need() { command -v "$1" >/dev/null || { echo "need $1"; exit 1; }; }
need curl; need jq; need openssl; need xxd; need python3

# Key + RID
openssl genpkey -algorithm Ed25519 -out "$work/ed25519.sk.pem" >/dev/null 2>&1
openssl pkey -in "$work/ed25519.sk.pem" -pubout -outform DER | tail -c 32 | xxd -p -c 32 > "$work/pk.hex"
python3 - "$work/pk.hex" > "$work/RID.txt" <<'PY'
import sys
ALPH="123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz"
pk=bytes.fromhex(open(sys.argv[1]).read().strip())
n=int.from_bytes(pk,'big'); s=""
while n>0: n,r=divmod(n,58); s=ALPH[r]+s
z=0
for b in pk:
    if b==0: z+=1
    else: break
print("1"*z + (s or "1"))
PY
RID=$(cat "$work/RID.txt"); echo "RID=$RID"

# Faucet + state
curl -s -X POST "http://127.0.0.1:${PORT}/faucet" -H 'Content-Type: application/json' \
  -d "{\"rid\":\"${RID}\",\"amount\":1000000}" | jq .
STATE=$(curl -s "http://127.0.0.1:${PORT}/balance/${RID}")
NONCE_CUR=$(jq -r .nonce <<<"$STATE"); NONCE=$((NONCE_CUR+1))
echo "nonce: $NONCE_CUR -> $NONCE"

# Canon
jq -n --arg f "$RID" --arg t "$RID" --argjson a "$AMOUNT" --argjson n "$NONCE" \
  '{tx:{from:$f,to:$t,amount:$a,nonce:$n}}' > "$work/canon_payload.json"
CANON_HEX=$(curl -s -X POST "http://127.0.0.1:${PORT}/debug_canon" -H 'Content-Type: application/json' \
  --data-binary @"$work/canon_payload.json" | jq -r .canon_hex)
echo -n "$CANON_HEX" | xxd -r -p > "$work/canon.bin"

# Sign
openssl pkeyutl -sign -rawin -inkey "$work/ed25519.sk.pem" -in "$work/canon.bin" -out "$work/sig.bin" >/dev/null 2>&1
SIG_HEX=$(xxd -p -c 256 "$work/sig.bin")

# Batch
jq -n --arg f "$RID" --arg t "$RID" --argjson a "$AMOUNT" --argjson n "$NONCE" --arg s "$SIG_HEX" \
  '{txs:[{from:$f,to:$t,amount:$a,nonce:$n,sig_hex:$s}]}' > "$work/batch.json"
curl -s -X POST "http://127.0.0.1:${PORT}/submit_tx_batch" -H 'Content-Type: application/json' \
  --data-binary @"$work/batch.json" | jq .

# Head / post state / metrics
echo "--- HEAD ---";         curl -s "http://127.0.0.1:${PORT}/head" | jq .
echo "--- POST ---";         curl -s "http://127.0.0.1:${PORT}/balance/${RID}" | jq .
echo "--- METRICS ---";      curl -s "http://127.0.0.1:${PORT}/metrics" \
 | grep -E "lrb_tx_|submit_tx_batch|http_inflight_requests" | head -n 40 || true
```

### `tools/./vegeta_submit.sh`

```
#!/usr/bin/env bash
set -euo pipefail

# --- дефолты ---
API="http://127.0.0.1:8080"
FROM="PAYER"
TO="RCV"
AMOUNT=1
RATE=500
DURATION="60s"
START_NONCE=1
COUNT=10000

# --- парсинг KEY=VALUE из аргументов ---
for kv in "$@"; do
  case "$kv" in
    API=*) API=${kv#API=} ;;
    FROM=*) FROM=${kv#FROM=} ;;
    TO=*) TO=${kv#TO=} ;;
    AMOUNT=*) AMOUNT=${kv#AMOUNT=} ;;
    RATE=*) RATE=${kv#RATE=} ;;
    DURATION=*) DURATION=${kv#DURATION=} ;;
    START_NONCE=*) START_NONCE=${kv#START_NONCE=} ;;
    COUNT=*) COUNT=${kv#COUNT=} ;;
    *) echo "[WARN] unknown arg: $kv" ;;
  esac
done

command -v vegeta >/dev/null 2>&1 || { echo "[ERR] vegeta not found in PATH"; exit 1; }

echo "[*] attack: rate=${RATE} for ${DURATION} | from=${FROM} to=${TO} amount=${AMOUNT} nonces=${START_NONCE}..$((START_NONCE+COUNT-1))"

gen_targets_json() {
  local n=${START_NONCE}
  local end=$((START_NONCE + COUNT - 1))
  while [[ $n -le $end ]]; do
    local body b64
    body=$(printf '{"from":"%s","to":"%s","amount":%d,"nonce":%d,"memo":"load","sig_hex":"00"}' \
      "$FROM" "$TO" "$AMOUNT" "$n")
    b64=$(printf '%s' "$body" | openssl base64 -A)
    printf '{"method":"POST","url":"%s/submit_tx","body":"%s","header":{"Content-Type":["application/json"]}}\n' \
      "$API" "$b64"
    n=$((n+1))
  done
}

# атака: live-репорт каждые 30s + финальные отчёты
gen_targets_json \
  | vegeta attack -format=json -rate="${RATE}" -duration="${DURATION}" \
  | tee results.bin \
  | vegeta report -every 30s

echo "[*] latency histogram:"
vegeta report -type='hist[0,500us,1ms,2ms,5ms,10ms,20ms,50ms,100ms]' results.bin

echo "[*] JSON metrics -> results.json"
vegeta report -type=json results.bin > results.json

# срез архива (если включён /archive)
if curl -sf "${API}/archive/history/${FROM}" >/dev/null 2>&1; then
  echo "[*] archive sample:"
  curl -sf "${API}/archive/history/${FROM}" | jq '.[0:5]' || true
fi
```

### `tools/./vegeta_submit_live.sh`

```
#!/usr/bin/env bash
set -euo pipefail

# === defaults ===
API="http://127.0.0.1:8080"
FROM="PAYER"
TO="RCV"
AMOUNT=1
RATE=500
DURATION="60s"
START_NONCE=1
COUNT=10000
REPORT_EVERY=30   # секунд

# === parse KEY=VALUE ===
for kv in "$@"; do
  case "$kv" in
    API=*) API=${kv#API=} ;;
    FROM=*) FROM=${kv#FROM=} ;;
    TO=*) TO=${kv#TO=} ;;
    AMOUNT=*) AMOUNT=${kv#AMOUNT=} ;;
    RATE=*) RATE=${kv#RATE=} ;;
    DURATION=*) DURATION=${kv#DURATION=} ;;
    START_NONCE=*) START_NONCE=${kv#START_NONCE=} ;;
    COUNT=*) COUNT=${kv#COUNT=} ;;
    REPORT_EVERY=*) REPORT_EVERY=${kv#REPORT_EVERY=} ;;
    *) echo "[WARN] unknown arg: $kv" ;;
  esac
done

command -v vegeta >/dev/null 2>&1 || { echo "[ERR] vegeta not found"; exit 1; }

echo "[*] attack: rate=${RATE} for ${DURATION} | from=${FROM} to=${TO} amount=${AMOUNT} nonces=${START_NONCE}..$((START_NONCE+COUNT-1))"

# === generate JSONL targets ===
TARGETS="targets.jsonl"
RESULTS="results.bin"
rm -f "$TARGETS" "$RESULTS"

gen_targets_json() {
  local n=${START_NONCE}
  local end=$((START_NONCE + COUNT - 1))
  while [[ $n -le $end ]]; do
    local body b64
    body=$(printf '{"from":"%s","to":"%s","amount":%d,"nonce":%d,"memo":"load","sig_hex":"00"}' \
      "$FROM" "$TO" "$AMOUNT" "$n")
    b64=$(printf '%s' "$body" | openssl base64 -A)
    printf '{"method":"POST","url":"%s/submit_tx","body":"%s","header":{"Content-Type":["application/json"]}}\n' \
      "$API" "$b64"
    n=$((n+1))
  done
}

gen_targets_json > "$TARGETS"

# === start attack in background ===
( vegeta attack -format=json -rate="${RATE}" -duration="${DURATION}" -targets="$TARGETS" > "$RESULTS" ) &
VEG_PID=$!

# cleanup & final report on Ctrl+C / TERM
finish() {
  echo
  echo "[*] stopping attack (pid=$VEG_PID) and printing final report..."
  kill "$VEG_PID" 2>/dev/null || true
  wait "$VEG_PID" 2>/dev/null || true

  echo "[*] FINAL SUMMARY:"
  vegeta report "$RESULTS"

  echo "[*] FINAL HISTOGRAM:"
  vegeta report -type='hist[0,500us,1ms,2ms,5ms,10ms,20ms,50ms,100ms]' "$RESULTS"

  echo "[*] JSON metrics -> results.json"
  vegeta report -type=json "$RESULTS" > results.json

  # archive sample (если включён /archive)
  if curl -sf "${API}/archive/history/${FROM}" >/dev/null 2>&1; then
    echo "[*] archive sample:"
    curl -sf "${API}/archive/history/${FROM}" | jq '.[0:5]' || true
  fi
  exit 0
}
trap finish INT TERM

# === live progress loop ===
START_TS=$(date +%s)
while kill -0 "$VEG_PID" 2>/dev/null; do
  sleep "$REPORT_EVERY"
  NOW=$(date +%s); ELAPSED=$((NOW-START_TS))
  echo
  echo "[*] PROGRESS t=${ELAPSED}s:"
  vegeta report "$RESULTS" || true
done

# wait and final when finished naturally
finish
```
